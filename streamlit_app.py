# -*- coding: utf-8 -*-
"""erlang-tjpe.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zjcdAWaWNKvv3HMFCPo3hLGuMgeR9Vaa
"""


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

import pyworkforce as pw
from pyworkforce.queuing import ErlangC


import pandas as pd
from pandasql import sqldf

df = pd.read_csv('IN.csv',delimiter=';',names=['ANO',	'MÊS',	'DIA',	'HORA',	'CANAL',	'qtd_ENTs',	'média_TMA',	'média_TME', 'maxTMA', 'maxTME'])

df.drop([0,1], axis=0, inplace=True)
df

query = "SELECT * FROM df WHERE CANAL='Telefonia' GROUP BY ANO, MÊS, DIA, HORA "

df_orders = sqldf(query)
df_orders.head()

#restringir ao canal de TELEFONIA:
query = "SELECT ANO, MÊS, DIA, HORA , SUM(qtd_ENTs) AS qtd_ENTs, AVG(média_TMA) AS média_TMA, AVG(média_TME) AS média_TME FROM df WHERE CANAL='Telefonia' GROUP BY ANO, MÊS, DIA, HORA "

#contando todos canais:
#query = "SELECT ANO, MÊS, DIA, HORA , SUM(qtd_ENTs) AS qtd_ENTs, AVG(média_TMA) AS média_TMA, AVG(média_TME) AS média_TME FROM df GROUP BY ANO, MÊS, DIA, HORA "


df_orders = sqldf(query)
df_orders.head()

df_ocuppa = pd.read_csv('ocuppacity.csv',delimiter=';', names = ['ANO',	'MÊS',	'DIA',	'nom_tecnico',	'Logiin',	'Logoout',	'SEGUNDOS_TOTAIS',	'SEGUNDOS_TOTAIS_naouteis',	'OccupancyRate'])

df_ocuppa

query = "SELECT AVG(OccupancyRate) AS média_Ocupação FROM df_ocuppa"

media_ocuppa = sqldf(query)
media_ocuppa = round(media_ocuppa.iloc[0]['média_Ocupação']/100, 2)

media_ocuppa

#QNTD DE tecnico por dia..em da tabela de ocupacao
query = "SELECT ANO, MÊS, DIA , COUNT(nom_tecnico) AS qtd_tecs FROM df_ocuppa GROUP BY ANO, MÊS, DIA"

df_qtdTecs = sqldf(query)

df_qtdTecs

"""Presença de Técnicos por hora"""

#@todo: VERIFICAR O CALCULO DA QUANTIDADE DE LIGAÇÕES extraidas nesse relatório.. ta dando diferente do somatório de outro relatório

df_tecHora = pd.read_csv('TECshorasPresentes.csv',delimiter=';',decimal='.')# names = [ 'nom_tecnico','ANO','MÊS' ,'DIA','castOnTime','castOffTime','07','08','09','10','11','12','13','14','15','16','17','18','19'])

df_tecHora['HORA'] = pd.to_datetime(df_tecHora['HORA']).dt.hour

df_tecHora

df_tecHora = df_tecHora.astype({"ANO":int, 	"MÊS":int,	"DIA":int, 	"HORA":int})
df_tecHora.dtypes

"""IN:


  transactions: float,
          The number of total transactions that comes in an interval.

  aht: float,
          Average handling time of a transaction (minutes).

  asa: float,
        The required average speed of answer (minutes).

  interval: int,
          Interval length (minutes) where the transactions come in

  shrinkage: float,
       Percentage of time that an operator unit is not available.





OUTPUT:

raw_positions: Number of positions found assuming shrinkage = 0

positions: Number of places found taking the shrinkage provided by the user

service_level: The expected percentage of transactions that don’t wait in the 
queue longer than the target ASA

occupancy: The expected occupancy that the system is going to have

waiting_probability: The probability that a transaction waits in the queue

"""

'''
erlang = ErlangC(transactions=100, aht=3, asa=20/60,  interval=60, shrinkage=0.3)

requirements = erlang.required_positions(service_level=0.8, max_occupancy=0.85)

 
print(requirements)

'''

erlang = ""


def categorise(row):  

  try:

    erlang = ErlangC(transactions=row['qtd_ENTs'], aht=row['média_TMA']/60, asa=row['média_TME']/60, interval=60, shrinkage=0.3)
    
    requirements = erlang.required_positions(service_level=0.8, max_occupancy=media_ocuppa)#0.85)

    #print('qtd_LIG= '+str(row['qtd_LIGs'])+'// média_TMA= '+str(row['média_TMA']))
    #print('requirements=' + str(requirements['occupancy']))

    row['raw_positions'] = requirements['raw_positions']
    row['positions'] = requirements['positions']
    row['service_level'] = requirements['service_level']
    row['occupancy'] = requirements['occupancy']
    row['waiting_probability'] = requirements['waiting_probability']


 
  except (ValueError, TypeError, RuntimeWarning):
    requirements=0
    row['raw_positions'] = 0
    row['positions'] = 0
    row['service_level'] = 0
    row['occupancy'] = 0
    row['waiting_probability'] = 0


    
  
  
  return row

'''
{'raw_positions': 14,
 'positions': 20,
 'service_level': 0.888,
 'occupancy': 0.714,
 'waiting_probability': 0.174}
'''


#df_orders['erlang'] = df_orders.apply(lambda row: categorise(row), axis=1)

#df_erlang = df_orders.apply(lambda row: categorise(row), axis=1)

df_erlang = df_orders.apply(lambda row: categorise(row), axis=1)
#pd.DataFrame.from_dict(your_dict,orient='index')

df_erlang

#LIMITANDO O ERLANg para o ano e mes de analise

query = "SELECT * FROM df_erlang WHERE ANO = 2022" # AND MÊS = 8"

df_erlang = sqldf(query)


df_erlang = df_erlang.astype({"ANO": int, "MÊS": int, 	"DIA": int, 	"HORA": int, 	"qtd_ENTs": int})

df_erlang

#result = pd.concat([df_erlang, df_tecHora ], axis=1, join="inner")

result = pd.merge(df_erlang, df_tecHora ,how='left', left_on=['ANO','MÊS','DIA','HORA'], right_on = ['ANO','MÊS','DIA','HORA'])

result.dtypes

# A diferença entre as quantidades de ligações é porque a MAIOR é A SOMA de todas interações entrantes (email+chat+tel)

#result = result.astype({"qtdDiasUteis": float, "TotalLIGs": int, 	"MédiaLIGs": float, 	"TotalAtds": int, 	"MédiaAtds": float, "Ligs/Atds":float})

result

result.describe()

plt.plot(result['DIA'], result['qtd_ENTs'])

result = result.drop('ANO', axis=1)
result = result.drop('MÊS', axis=1)
result = result.drop('DIA', axis=1)
result = result.drop('qtdDiasUteis', axis=1)

result

figure = plt.figure(figsize=(25,20))


corr = result.corr()

mask = np.triu(np.ones_like(corr, dtype=bool))

sns.heatmap(corr,mask = mask, annot = True, cmap='coolwarm')

plt.figure(figsize=(15,8))
plt.plot(result['HORA'], result['TotalLIGs'])
